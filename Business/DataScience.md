# Data Science

Data science for data from web/mobile
Machine learning for data in computer science
Business analytics for data on customers

1. Getting data (RAW DATA)
Access and get data from different sources

2. Clean data (PROCESSED DATA)
Put the data into the model and format you desire

3. Merge data (PROCESSED DATA)
If needed, merge data from different sources (mapping)

Types of Data Science Questions:

Descriptive (Describe a set of data)
Exploratory (Find relationships you didn't know about)
Inferential (Use small sample to say something about the whole)
Predictive (Use data on some objects to predict for another object)
Causal (What happens to one variable, when you make change to another variable)
Mechanistic (Understand exact changes in variables that lead to changes in other variables)

Data is the second most important thing in data science. The question you're trying to answer is the most important thing.

1. Big Data Infrastructure — Learn the pros and cons of a wide variety of 
open-source big data technologies. Install a data infrastructure that allows for 
the distributed processing of large data sets across clusters of computers, 
makes appropriate technology trade-offs and optimally solves the problem 
your data project is trying to address. 

2. Extracting data — Build a robust data collection system, which reliably 
extracts relevant data from server logs, internal relational databases, or 
external data sources or web crawlers. 
3. Transforming data — Transform, clean and normalize data to so it 
matches the analysis objectives of the project. Create a system that does this 
automatically, ensuring data consistency and quality. 

4. Loading / Storing data — Choose the appropriate data store, set it up 
and load your data across multiple cloud-based server instances. Ensure that 
data store is scalable, performant and easily accessible via a universal API. 

5. Building visualizations and dashboards — Create a set of 
monitoring tools and visualizations that will allow you and others to monitor 
the status of your ETL (Extract, Transform, Load) data pipeline and visualize 
trends, anomalies in the underlying data. 
To accomplish the above you will use open-source big data technologies and 
select the ones that are most appropriate for your problem. That said, the 
mentors will focus your attention on the technologies and tools that they 
themselves use at their companies, so that you can get experience that is directly 
applicable to what you will be doing on the job. 

Technologies used by mentor companies and that you may implement in your 
projects include: MySQL, Hadoop, HBase, Hive, Pig, Cassandra, Zookeeper, 
Storm, Spark, Presto, Kafka, Solr and others. 

raw data --> processing script --> tidy data --> data analysis --> data communication

General Funnel:
1. GET
1.1 Acquire
  Active User (Type, Source)
  Click Through Rates
  Conversion (Source)
  Cost Per Acquisition
1.2 Activate
  Bounce Rates
2. KEEP
2.1 Retain
  Retention
    Cohort Analysis (Source)
3. GROW
3.1 Refer
  Percentage of referring Users
  Avg. Number of referrals per User
  Conversion of referrals
  Viral Growth Factor (K-Factor)
3.2 Revenue
  Monthly Reccurring Revenue
  Churn Rate
  Lifetime Value

Flipbook
Acquisition Channel
Selling Tactic
Revenue Model
Product Type
Delivery Model

Financial:
1. Cash burn rate
2. Run rate (months)

A good metric:
Understandable
Comparative
A ratio or rate
Behaviour changing!

Qualitative:
Unstructured, hard to aggregate

Quantitative:
Numbers, stats, hard facts, less insights

Exploratory:
Speculative, Find the unexpected, creates advantages

Reporting:
Predictable, day-to-day, necessary

Rumsfeld:
Thing we know we know = facts
Things we know we don't know = questions
Things we don't know we know = intuition
Things we don't we don't know = exploration

Lagging:
Historical, examples: sales

Leading:
Forward-looking, predictive example: pipeline

Correlated:
Two variables are related but may depend on something else

Causal:
An independent variable that impacts a dependent one

Engagement Metrics
Follow back within 3 days
7 friends within 10 days

Growth hacking:
Pick a metric to change --> Find correlation --> Test causality --> Optimize the causal factor

Engines of Growth:
Stickiness - retain users - get customers faster than you loose them
Virality - make people invite friends - How many invite friends
Price - Spend money to get customers - Customer are worth more than costs

Engagement:
Days since last engagement

1. Large-scale data analytics
2. Statistical Analysis & Machine Learning

Lean Analytics Cycle:
1. Pick a metric
2. Draw a line
3. Find a potential improvement (without or with data)
4. Define hypothesis
5. Make changes in production / or A/B test / experiment
6. Measure the results
7. Did we move the needle?
8. Success or pivot or draw a new line

Problem with Data:
1. Data-privacy
2. Correlation vs. Causality
3. Representativeness
4. Quality

1. Metric - Figure out what to improve
2. Hypothesis - Make an educated guess
3. Experiment - Test your guess
4. Act - Decide what's next

Make three assumptions
Define three actions to take
Run three experiments
Metric needs to be behavior changing

Matchday to matchday retention / churn

Micro conversions:
1. article read
2. match followed
3. certain section viewed
4. Push activated
5. Team set

Makro conversion:
1. Signup

Big data
0. Transform vague questions to measurable hypothesis (Question first)
1. Unified logging / architecture / infrastructure / ETL / cleaning - data engineer
2. Mining, data science, regression models, predictive modeling - data scientist
3. Communication / telling a story / reporting / actionable insights - data analyst

Process

1. Identify problem
2. Instrument data sources
3. Collect data
4. Prepare data (integrate, transform, clean, impute, filter, aggregate)
5. Build model
6. Evaluate model
7. Communicate results

Dataists process

1. Obtain
2. Scrub
3. Explore
4. Model
5. Interpret

Process Jim Gray

1. Capture
2. Curate
3. Communicate

1. Scoping - Why before how
Picking the right techniques is secondary to ask the right questions
1.1 Context of project (Exposition)
Problem, Goal, Stakeholders, Decision makers
1.2 Needs the projects needs to meet (Conflict)
What needs to be fixed, Design - steps to create knowledge
1.3 Vision of what success looks like (Resolution)
Mockups, sketch, sentences
1.4 Outcome - prediction of result (Happily ever after)
What goal? How measured, Who will use, why?

Principles for graphics

1. Show Comparison
2. Show Causality, mechanism, explanation
3. Show multivariate data
4. Integration multiple modes of evidence
5. Describe and document evidence
6. Content is king (whats the story, quality, relevance etc.)

Why graphs?

1. Understand data properties
2. Find patterns
3. Suggest modeling strategies
4. Debug analyses
5. Communicate results

Steps in data analysis
1. Define question
2. Define ideal dataset
3. Determine what data you can acess
4. Obtain the data
5. Clean the data
6. Exploratory data analysis
7. Statistical prediction / modeling
8. Interpret results
9. Challenge results
10. Synthesize / write up results
11. Create reproducible code

